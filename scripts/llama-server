#!/bin/sh

# For multimodal, use '--mmproj' with the image model. For example:
#
#     MODEL=../../models/Qwen3-VL-30B-A3B-Instruct-Q4_0.gguf ./llama-server --mmproj ../../models/mmproj-F16.gguf

context=${CONTEXT:-400000}
model=${MODEL:-'../../models/Qwen3-Coder-Next-Q4_0.gguf'}

../../llama.cpp/build/bin/llama-server \
  -m $model \
  -ngl 999 \
  --ctx-size $context \
  -c $context \
  -n 8192 \
  -b 2048 \
  --no-mmap \
  --parallel 4 \
  --temp 0.1 \
  --top-p 0.9 \
  --host 0.0.0.0 $@
